{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3Vf1Q79XPQ3D",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan  7 05:27:42 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.98                 Driver Version: 535.98       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        On  | 00000000:8A:00.0 Off |                  N/A |\n",
      "|  0%   30C    P8              16W / 350W |      2MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uRLTiuIuqGNc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pdb\n",
    "import pprint\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import tqdm.auto as tqdm\n",
    "from pathlib import Path\n",
    "from argparse import Namespace\n",
    "from fairseq import utils\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0n07Za1XqJzA"
   },
   "source": [
    "# Fix random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xllxxyWxqI7s",
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 73\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  \n",
    "np.random.seed(seed)  \n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQw2mY4Dqkzd"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "SXT42xQtqijD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = './DATA/rawdata'\n",
    "dataset_name = 'translation2019'\n",
    "prefix = Path(data_dir).absolute() / dataset_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLkJwNiFrIwZ"
   },
   "source": [
    "## Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_uJYkCncrKJb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "src_lang = 'en'\n",
    "tgt_lang = 'zh'\n",
    "\n",
    "data_prefix = f'{prefix}/train_dev.raw'\n",
    "test_prefix = f'{prefix}/test.raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0t2CPt1brOT3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slipshod assistance , foolish inattention , dowdy indifference , & halfhearted work seem the rule ;\n",
      "The product adopt outstanding black extinction cloth with soft nap on the inner side , to eliminate the environment light disturbance and the monitor light selfreflection effectively .\n",
      "Europe has about 5 . 3 million rooms .\n",
      "Note:Cover for cable tray Modle T103 is available . In making an order , just indicate the tape of cover whose weight is exclusive .\n",
      "A pound doesn't go far these days .\n",
      "工作上拖拖拉拉、漫不经心、三心二意似乎已成常态 ;\n",
      "产品内侧采用性能优异的黑色消光绒面 , 有效的消除环境光线的干扰和显示器自身光线的反射 。\n",
      "欧洲的客房更高达530万间 。\n",
      "注:T1-03弯通桥架备有护罩 , 需订护罩请在订货时按型号注明 , 重量另计 。\n",
      "现今一英镑不经一用 。\n"
     ]
    }
   ],
   "source": [
    "!head {data_prefix+'.'+src_lang} -n 5\n",
    "!head {data_prefix+'.'+tgt_lang} -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRoE9UK7r1gY"
   },
   "source": [
    "## Preprocess files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3tzFwtnFrle3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def strQ2B(ustring):\n",
    "    \"\"\"Full width -> half width\"\"\"\n",
    "    ss = []\n",
    "    for s in ustring:\n",
    "        rstring = \"\"\n",
    "        for uchar in s:\n",
    "            inside_code = ord(uchar)\n",
    "            if inside_code == 12288:  # Full width space: direct conversion\n",
    "                inside_code = 32\n",
    "            elif (inside_code >= 65281 and inside_code <= 65374):  # Full width chars (except space) conversion\n",
    "                inside_code -= 65248\n",
    "            rstring += chr(inside_code)\n",
    "        ss.append(rstring)\n",
    "    return ''.join(ss)\n",
    "                \n",
    "def clean_s(s, lang):\n",
    "    if lang == 'en':\n",
    "        s = re.sub(r\"\\([^()]*\\)\", \"\", s) # remove ([text])\n",
    "        s = s.replace('-', '') # remove '-'\n",
    "        s = re.sub('([.,;!?()\\\"])', r' \\1 ', s) # keep punctuation\n",
    "    elif lang == 'zh':\n",
    "        s = strQ2B(s) # Q2B\n",
    "        s = re.sub(r\"\\([^()]*\\)\", \"\", s) # remove ([text])\n",
    "        s = s.replace(' ', '')\n",
    "        s = s.replace('—', '')\n",
    "        s = s.replace('“', '\"')\n",
    "        s = s.replace('”', '\"')\n",
    "        s = s.replace('_', '')\n",
    "        s = re.sub('([。,;!?()\\\"~「」])', r' \\1 ', s) # keep punctuation\n",
    "    s = ' '.join(s.strip().split())\n",
    "    return s\n",
    "\n",
    "def len_s(s, lang):\n",
    "    if lang == 'zh':\n",
    "        return len(s)\n",
    "    return len(s.split())\n",
    "\n",
    "def clean_corpus(prefix, l1, l2, ratio=9, max_len=1000, min_len=1):\n",
    "    if Path(f'{prefix}.clean.{l1}').exists() and Path(f'{prefix}.clean.{l2}').exists():\n",
    "        print(f'{prefix}.clean.{l1} & {l2} exists. skipping clean.')\n",
    "        return\n",
    "    with open(f'{prefix}.{l1}', 'r') as l1_in_f:\n",
    "        with open(f'{prefix}.{l2}', 'r') as l2_in_f:\n",
    "            with open(f'{prefix}.clean.{l1}', 'w') as l1_out_f:\n",
    "                with open(f'{prefix}.clean.{l2}', 'w') as l2_out_f:\n",
    "                    for s1 in l1_in_f:\n",
    "                        s1 = s1.strip()\n",
    "                        s2 = l2_in_f.readline().strip()\n",
    "                        s1 = clean_s(s1, l1)\n",
    "                        s2 = clean_s(s2, l2)\n",
    "                        s1_len = len_s(s1, l1)\n",
    "                        s2_len = len_s(s2, l2)\n",
    "                        if min_len > 0: # remove short sentence\n",
    "                            if s1_len < min_len or s2_len < min_len:\n",
    "                                continue\n",
    "                        if max_len > 0: # remove long sentence\n",
    "                            if s1_len > max_len or s2_len > max_len:\n",
    "                                continue\n",
    "                        if ratio > 0: # remove by ratio of length\n",
    "                            if s1_len/s2_len > ratio or s2_len/s1_len > ratio:\n",
    "                                continue\n",
    "                        print(s1, file=l1_out_f)\n",
    "                        print(s2, file=l2_out_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "h_i8b1PRr9Nf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_corpus(data_prefix, src_lang, tgt_lang)\n",
    "clean_corpus(test_prefix, src_lang, tgt_lang, ratio=-1, min_len=-1, max_len=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "gjT3XCy9r_rj",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slipshod assistance , foolish inattention , dowdy indifference , & halfhearted work seem the rule ;\n",
      "The product adopt outstanding black extinction cloth with soft nap on the inner side , to eliminate the environment light disturbance and the monitor light selfreflection effectively .\n",
      "Europe has about 5 . 3 million rooms .\n",
      "Note:Cover for cable tray Modle T103 is available . In making an order , just indicate the tape of cover whose weight is exclusive .\n",
      "A pound doesn't go far these days .\n",
      "工作上拖拖拉拉、漫不经心、三心二意似乎已成常态 ;\n",
      "产品内侧采用性能优异的黑色消光绒面 , 有效的消除环境光线的干扰和显示器自身光线的反射 。\n",
      "欧洲的客房更高达530万间 。\n",
      "注:T1-03弯通桥架备有护罩 , 需订护罩请在订货时按型号注明 , 重量另计 。\n",
      "现今一英镑不经一用 。\n"
     ]
    }
   ],
   "source": [
    "!head {data_prefix+'.clean.'+src_lang} -n 5\n",
    "!head {data_prefix+'.clean.'+tgt_lang} -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKb4u67-sT_Z"
   },
   "source": [
    "## Split into train/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AuFKeDz3sGHL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_ratio = 0.01 \n",
    "train_ratio = 1 - valid_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "QR2NVldqsXyY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if (prefix/f'train.clean.{src_lang}').exists() \\\n",
    "and (prefix/f'train.clean.{tgt_lang}').exists() \\\n",
    "and (prefix/f'valid.clean.{src_lang}').exists() \\\n",
    "and (prefix/f'valid.clean.{tgt_lang}').exists():\n",
    "    print(f'train/valid splits exists. skipping split.')\n",
    "else:\n",
    "    line_num = sum(1 for line in open(f'{data_prefix}.clean.{src_lang}'))\n",
    "    labels = list(range(line_num))\n",
    "    random.shuffle(labels)\n",
    "    for lang in [src_lang, tgt_lang]:\n",
    "        train_f = open(os.path.join(data_dir, dataset_name, f'train.clean.{lang}'), 'w')\n",
    "        valid_f = open(os.path.join(data_dir, dataset_name, f'valid.clean.{lang}'), 'w')\n",
    "        count = 0\n",
    "        for line in open(f'{data_prefix}.clean.{lang}', 'r'):\n",
    "            if labels[count]/line_num < train_ratio:\n",
    "                train_f.write(line)\n",
    "            else:\n",
    "                valid_f.write(line)\n",
    "            count += 1\n",
    "        train_f.close()\n",
    "        valid_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1rwQysTsdJq"
   },
   "source": [
    "## Subword Units "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ecwllsa7sZRA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "vocab_size = 32000\n",
    "if (prefix/f'spm{vocab_size}.model').exists():\n",
    "    print(f'{prefix}/spm{vocab_size}.model exists. skipping spm_train.')\n",
    "else:\n",
    "    spm.SentencePieceTrainer.train(\n",
    "        input=','.join([f'{prefix}/train.clean.{src_lang}',\n",
    "                        f'{prefix}/valid.clean.{src_lang}',\n",
    "                        f'{prefix}/train.clean.{tgt_lang}',\n",
    "                        f'{prefix}/valid.clean.{tgt_lang}']),\n",
    "        model_prefix=prefix/f'spm{vocab_size}',\n",
    "        vocab_size=vocab_size,\n",
    "        character_coverage=1,\n",
    "        model_type='unigram', # 'bpe' works as well\n",
    "        input_sentence_size=1e6,\n",
    "        shuffle_input_sentence=True,\n",
    "        normalization_rule_name='nmt_nfkc_cf',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "lQPRNldqse_V",
    "tags": []
   },
   "outputs": [],
   "source": [
    "spm_model = spm.SentencePieceProcessor(model_file=str(prefix/f'spm{vocab_size}.model'))\n",
    "in_tag = {\n",
    "    'train': 'train.clean',\n",
    "    'valid': 'valid.clean',\n",
    "    'test': 'test.raw.clean',\n",
    "}\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    for lang in [src_lang, tgt_lang]:\n",
    "        out_path = prefix/f'{split}.{lang}'\n",
    "        if out_path.exists():\n",
    "            print(f\"{out_path} exists. skipping spm_encode.\")\n",
    "        else:\n",
    "            with open(prefix/f'{split}.{lang}', 'w') as out_f:\n",
    "                with open(prefix/f'{in_tag[split]}.{lang}', 'r') as in_f:\n",
    "                    for line in in_f:\n",
    "                        line = line.strip()\n",
    "                        tok = spm_model.encode(line, out_type=str)\n",
    "                        print(' '.join(tok), file=out_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "4j6lXHjAsjXa",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁slip sh od ▁assistance ▁, ▁foolish ▁in att ent ion ▁, ▁dow dy ▁in di ffer ence ▁, ▁& ▁half hearted ▁work ▁seem ▁the ▁rule ▁;\n",
      "▁the ▁product ▁adopt ▁outstanding ▁black ▁extinction ▁cloth ▁with ▁soft ▁nap ▁on ▁the ▁inner ▁side ▁, ▁to ▁eliminate ▁the ▁environment ▁light ▁disturbance ▁and ▁the ▁monitor ▁light ▁self re fl ection ▁effective ly ▁.\n",
      "▁europe ▁has ▁about ▁5 ▁. ▁3 ▁million ▁rooms ▁.\n",
      "▁note : cover ▁for ▁cable ▁tray ▁ mod le ▁t 10 3 ▁is ▁available ▁. ▁in ▁making ▁an ▁order ▁, ▁just ▁indicate ▁the ▁tape ▁of ▁cover ▁whose ▁weight ▁is ▁exclusive ▁.\n",
      "▁a ▁pound ▁doesn ' t ▁go ▁far ▁these ▁days ▁.\n",
      "▁ 工作 上 拖 拖 拉 拉 、 漫 不 经 心 、 三 心 二 意 似乎 已 成 常 态 ▁;\n",
      "▁产品 内 侧 采用 性能 优异 的 黑色 消 光 绒 面 ▁, ▁ 有效的 消除 环境 光线 的 干扰 和 显示器 自身 光线 的 反射 ▁。\n",
      "▁欧洲 的 客房 更 高达 5 30 万 间 ▁。\n",
      "▁ 注 : t 1 - 03 弯 通 桥 架 备 有 护 罩 ▁, ▁ 需 订 护 罩 请 在 订 货 时 按 型号 注 明 ▁, ▁ 重量 另 计 ▁。\n",
      "▁ 现今 一 英镑 不 经 一 用 ▁。\n"
     ]
    }
   ],
   "source": [
    "!head {data_dir+'/'+dataset_name+'/train.'+src_lang} -n 5\n",
    "!head {data_dir+'/'+dataset_name+'/train.'+tgt_lang} -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59si_C0Wsms7"
   },
   "source": [
    "## Binarize the data with fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w-cHVLSpsknh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "binpath = Path('./DATA/data-bin', dataset_name)\n",
    "if binpath.exists():\n",
    "    print(binpath, \"exists, will not overwrite!\")\n",
    "else:\n",
    "    !python -m fairseq_cli.preprocess \\\n",
    "        --source-lang {src_lang}\\\n",
    "        --target-lang {tgt_lang}\\\n",
    "        --trainpref {prefix/'train'}\\\n",
    "        --validpref {prefix/'valid'}\\\n",
    "        --testpref {prefix/'test'}\\\n",
    "        --destdir {binpath}\\\n",
    "        --joined-dictionary\\\n",
    "        --workers 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "szMuH1SWLPWA"
   },
   "source": [
    "# Configuration for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "5Luz3_tVLUxs",
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = Namespace(\n",
    "    datadir = \"./DATA/data-bin/translation2019\",\n",
    "    # savedir = \"./checkpoints/rnn\",\n",
    "    savedir = \"./checkpoints/transformer\",\n",
    "    source_lang = \"en\",\n",
    "    target_lang = \"zh\",\n",
    "    \n",
    "    # cpu threads when fetching & processing data.\n",
    "    num_workers=2,  \n",
    "    # batch size in terms of tokens. gradient accumulation increases the effective batchsize.\n",
    "    max_tokens=8192,\n",
    "    accum_steps=2,\n",
    "    \n",
    "    # the lr s calculated from Noam lr scheduler. you can tune the maximum lr by this factor.\n",
    "    lr_factor=2.,\n",
    "    lr_warmup=4000,\n",
    "    \n",
    "    # clipping gradient norm helps alleviate gradient exploding\n",
    "    clip_norm=1.0,\n",
    "    \n",
    "    # maximum epochs for training\n",
    "    max_epoch=30,\n",
    "    start_epoch=1,\n",
    "    \n",
    "    # beam size for beam search\n",
    "    beam=5, \n",
    "    # generate sequences of maximum length ax + b, where x is the source length\n",
    "    max_len_a=1.2, \n",
    "    max_len_b=10, \n",
    "    # when decoding, post process sentence by removing sentencepiece symbols and jieba tokenization.\n",
    "    post_process = \"sentencepiece\",\n",
    "    \n",
    "    # checkpoints\n",
    "    keep_last_epochs=5,\n",
    "    resume=None, # if resume from checkpoint name (under config.savedir)\n",
    "    \n",
    "    # logging\n",
    "    use_wandb=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjrJFvyQLg86"
   },
   "source": [
    "# Logging\n",
    "- logging package logs ordinary messages\n",
    "- wandb logs the loss, bleu, etc. in the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "-ZiMyDWALbDk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    level=\"INFO\", # \"DEBUG\" \"WARNING\" \"ERROR\"\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "proj = \"hw5.seq2seq\"\n",
    "logger = logging.getLogger(proj)\n",
    "if config.use_wandb:\n",
    "    import wandb\n",
    "    wandb.init(project=proj, name=Path(config.savedir).stem, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNoSkK45Lmqc"
   },
   "source": [
    "# CUDA Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "oqrsbmcoLqMl",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-06 23:45:20 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
      "2024-01-06 23:45:20 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 \n",
      "2024-01-06 23:45:20 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n"
     ]
    }
   ],
   "source": [
    "cuda_env = utils.CudaEnvironment()\n",
    "utils.CudaEnvironment.pretty_print_cuda_env_list([cuda_env])\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbJuBIHLLt2D"
   },
   "source": [
    "# Dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "3gSEy1uFLvVs",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-06 23:45:25 | INFO | fairseq.tasks.translation | [en] dictionary: 33624 types\n",
      "2024-01-06 23:45:25 | INFO | fairseq.tasks.translation | [zh] dictionary: 33624 types\n"
     ]
    }
   ],
   "source": [
    "from fairseq.tasks.translation import TranslationConfig, TranslationTask\n",
    "\n",
    "## setup task\n",
    "task_cfg = TranslationConfig(\n",
    "    data=config.datadir,\n",
    "    source_lang=config.source_lang,\n",
    "    target_lang=config.target_lang,\n",
    "    train_subset=\"train\",\n",
    "    required_seq_len_multiple=8,\n",
    "    dataset_impl=\"mmap\",\n",
    "    upsample_primary=1,\n",
    ")\n",
    "task = TranslationTask.setup_task(task_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mR7Bhov7L4IU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger.info(\"loading data for epoch 1\")\n",
    "task.load_dataset(split=\"train\", epoch=1, combine=True)\n",
    "task.load_dataset(split=\"valid\", epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "P0BCEm_9L6ig",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1,\n",
      " 'source': tensor([2586,   47, 5767,  720, 4029, 1242,   94,   19,    5, 9448,  414,    4,\n",
      "        1281,   23,   13,    5,  305,  414,    7,    2]),\n",
      " 'target': tensor([    6, 19860,   533,    47,     4,     6,  9098,   599,    11, 27324,\n",
      "         5477,     4,     6,    18,  7389,  2573,    38,   881,    11,     8,\n",
      "            2])}\n",
      "('Source: remember ? alcoholism rates went up for the intervention group , '\n",
      " 'compared to the control group .')\n",
      "'Target: 还记得吗 ? , 干预组的酗酒比例 , 和对照组相比是增加的 。'\n"
     ]
    }
   ],
   "source": [
    "sample = task.dataset(\"valid\")[1]\n",
    "pprint.pprint(sample)\n",
    "pprint.pprint(\n",
    "    \"Source: \" + \\\n",
    "    task.source_dictionary.string(\n",
    "        sample['source'],\n",
    "        config.post_process,\n",
    "    )\n",
    ")\n",
    "pprint.pprint(\n",
    "    \"Target: \" + \\\n",
    "    task.target_dictionary.string(\n",
    "        sample['target'],\n",
    "        config.post_process,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UcfCVa2FMBSE"
   },
   "source": [
    "# Dataset iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "OWFJFmCnMDXW",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-06 23:45:40 | WARNING | fairseq.tasks.fairseq_task | 14,324 samples have invalid sizes and will be skipped, max_positions=(20, 20), first few sample ids=[16343, 10080, 9181, 3595, 12852, 9309, 12384, 7888, 2956, 4638]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': tensor([18143]),\n",
       " 'nsentences': 1,\n",
       " 'ntokens': 10,\n",
       " 'net_input': {'src_tokens': tensor([[    1,     1,     1,    37,   903,     5, 14352,   211, 12669,    17,\n",
       "             244,  1443,  4955,   321,     7,     2]]),\n",
       "  'src_lengths': tensor([13]),\n",
       "  'prev_output_tokens': tensor([[    2,   233,  2599, 14562, 18929,    38,   658,  1209,    11,     8,\n",
       "               1,     1,     1,     1,     1,     1]])},\n",
       " 'target': tensor([[  233,  2599, 14562, 18929,    38,   658,  1209,    11,     8,     2,\n",
       "              1,     1,     1,     1,     1,     1]])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data_iterator(task, split, epoch=1, max_tokens=4000, num_workers=1, cached=True):\n",
    "    batch_iterator = task.get_batch_iterator(\n",
    "        dataset=task.dataset(split),\n",
    "        max_tokens=max_tokens,\n",
    "        max_sentences=None,\n",
    "        max_positions=utils.resolve_max_positions(\n",
    "            task.max_positions(),\n",
    "            max_tokens,\n",
    "        ),\n",
    "        ignore_invalid_inputs=True,\n",
    "        seed=seed,\n",
    "        num_workers=num_workers,\n",
    "        epoch=epoch,\n",
    "        disable_iterator_cache=not cached,\n",
    "    )\n",
    "    return batch_iterator\n",
    "\n",
    "demo_epoch_obj = load_data_iterator(task, \"valid\", epoch=1, max_tokens=20, num_workers=1, cached=False)\n",
    "demo_iter = demo_epoch_obj.next_epoch_itr(shuffle=True)\n",
    "sample = next(demo_iter)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EyDBE5ZMkFZ"
   },
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Hzh74qLIMfW_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fairseq.models import (\n",
    "    FairseqEncoder, \n",
    "    FairseqIncrementalDecoder,\n",
    "    FairseqEncoderDecoderModel\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDAPmxjRNEEL"
   },
   "source": [
    "## Seq2Seq\n",
    "- Composed of **Encoder** and **Decoder**\n",
    "- Recieves inputs and pass to **Encoder** \n",
    "- Pass the outputs from **Encoder** to **Decoder**\n",
    "- **Decoder** will decode according to outputs of previous timesteps as well as **Encoder** outputs  \n",
    "- Once done decoding, return the **Decoder** outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "oRwKdLa0NEU6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(FairseqEncoderDecoderModel):\n",
    "    def __init__(self, args, encoder, decoder):\n",
    "        super().__init__(encoder, decoder)\n",
    "        self.args = args\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        src_tokens,\n",
    "        src_lengths,\n",
    "        prev_output_tokens,\n",
    "        return_all_hiddens: bool = True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Run the forward pass for an encoder-decoder model.\n",
    "        \"\"\"\n",
    "        encoder_out = self.encoder(\n",
    "            src_tokens, src_lengths=src_lengths, return_all_hiddens=return_all_hiddens\n",
    "        )\n",
    "        logits, extra = self.decoder(\n",
    "            prev_output_tokens,\n",
    "            encoder_out=encoder_out,\n",
    "            src_lengths=src_lengths,\n",
    "            return_all_hiddens=return_all_hiddens,\n",
    "        )\n",
    "        return logits, extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zu3C2JfqNHzk"
   },
   "source": [
    "# Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "nyI9FOx-NJ2m",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transformer architecture\n",
    "from fairseq.models.transformer import (\n",
    "    TransformerEncoder, \n",
    "    TransformerDecoder,\n",
    ")\n",
    "\n",
    "def build_model(args, task):\n",
    "    \"\"\" build a model instance based on hyperparameters \"\"\"\n",
    "    src_dict, tgt_dict = task.source_dictionary, task.target_dictionary\n",
    "\n",
    "    # token embeddings\n",
    "    encoder_embed_tokens = nn.Embedding(len(src_dict), args.encoder_embed_dim, src_dict.pad())\n",
    "    decoder_embed_tokens = nn.Embedding(len(tgt_dict), args.decoder_embed_dim, tgt_dict.pad())\n",
    "    \n",
    "    # encoder decoder\n",
    "    encoder = TransformerEncoder(args, src_dict, encoder_embed_tokens)\n",
    "    decoder = TransformerDecoder(args, tgt_dict, decoder_embed_tokens)\n",
    "\n",
    "    # sequence to sequence model\n",
    "    model = Seq2Seq(args, encoder, decoder)\n",
    "    \n",
    "    # initialization for seq2seq model is important, requires extra handling\n",
    "    def init_params(module):\n",
    "        from fairseq.modules import MultiheadAttention\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        if isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        if isinstance(module, MultiheadAttention):\n",
    "            module.q_proj.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            module.k_proj.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            module.v_proj.weight.data.normal_(mean=0.0, std=0.02)\n",
    "        if isinstance(module, nn.RNNBase):\n",
    "            for name, param in module.named_parameters():\n",
    "                if \"weight\" in name or \"bias\" in name:\n",
    "                    param.data.uniform_(-0.1, 0.1)\n",
    "            \n",
    "    # weight initialization\n",
    "    model.apply(init_params)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce5n4eS7NQNy"
   },
   "source": [
    "## Architecture Related Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Cyn30VoGNT6N",
    "tags": []
   },
   "outputs": [],
   "source": [
    "arch_args = Namespace(\n",
    "    encoder_embed_dim=256,\n",
    "    encoder_ffn_embed_dim=1024,\n",
    "    encoder_layers=4,\n",
    "    decoder_embed_dim=256,\n",
    "    decoder_ffn_embed_dim=1024,\n",
    "    decoder_layers=4,\n",
    "    share_decoder_input_output_embed=True,\n",
    "    dropout=0.15,\n",
    ")\n",
    "\n",
    "def add_transformer_args(args):\n",
    "    args.encoder_attention_heads=4\n",
    "    args.encoder_normalize_before=True\n",
    "    \n",
    "    args.decoder_attention_heads=4\n",
    "    args.decoder_normalize_before=True\n",
    "    \n",
    "    args.activation_fn=\"relu\"\n",
    "    args.max_source_positions=1024\n",
    "    args.max_target_positions=1024\n",
    "    \n",
    "    from fairseq.models.transformer import base_architecture\n",
    "    base_architecture(arch_args)\n",
    "\n",
    "add_transformer_args(arch_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Nbb76QLCNZZZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config.use_wandb:\n",
    "    wandb.config.update(vars(arch_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "7ZWfxsCDNatH",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-06 23:45:55 | INFO | hw5.seq2seq | Seq2Seq(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(33624, 256, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(33624, 256, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (output_projection): Linear(in_features=256, out_features=33624, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = build_model(arch_args, task)\n",
    "logger.info(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHll7GRNNdqc"
   },
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUB9f1WCNgMH"
   },
   "source": [
    "## Loss: Label Smoothing Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "IgspdJn0NdYF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LabelSmoothedCrossEntropyCriterion(nn.Module):\n",
    "    def __init__(self, smoothing, ignore_index=None, reduce=True):\n",
    "        super().__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.ignore_index = ignore_index\n",
    "        self.reduce = reduce\n",
    "    \n",
    "    def forward(self, lprobs, target):\n",
    "        if target.dim() == lprobs.dim() - 1:\n",
    "            target = target.unsqueeze(-1)\n",
    "        nll_loss = -lprobs.gather(dim=-1, index=target)\n",
    "        #  reserve some probability for other labels. thus when calculating cross-entropy, \n",
    "        # equivalent to summing the log probs of all labels\n",
    "        smooth_loss = -lprobs.sum(dim=-1, keepdim=True)\n",
    "        if self.ignore_index is not None:\n",
    "            pad_mask = target.eq(self.ignore_index)\n",
    "            nll_loss.masked_fill_(pad_mask, 0.0)\n",
    "            smooth_loss.masked_fill_(pad_mask, 0.0)\n",
    "        else:\n",
    "            nll_loss = nll_loss.squeeze(-1)\n",
    "            smooth_loss = smooth_loss.squeeze(-1)\n",
    "        if self.reduce:\n",
    "            nll_loss = nll_loss.sum()\n",
    "            smooth_loss = smooth_loss.sum()\n",
    "        # when calculating cross-entropy, add the loss of other labels\n",
    "        eps_i = self.smoothing / lprobs.size(-1)\n",
    "        loss = (1.0 - self.smoothing) * nll_loss + eps_i * smooth_loss\n",
    "        return loss\n",
    "\n",
    "# generally, 0.1 is good enough\n",
    "criterion = LabelSmoothedCrossEntropyCriterion(\n",
    "    smoothing=0.1,\n",
    "    ignore_index=task.target_dictionary.pad(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRalDto2NkJJ"
   },
   "source": [
    "## Optimizer: Adam + lr scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "sS7tQj1ROBYm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_rate(d_model, step_num, warmup_step):\n",
    "    lr = (d_model**(-0.5)) * min(step_num**(-0.5), step_num*(warmup_step**(-1.5)))\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "J8hoAjHPNkh3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "    \n",
    "    @property\n",
    "    def param_groups(self):\n",
    "        return self.optimizer.param_groups\n",
    "        \n",
    "    def multiply_grads(self, c):\n",
    "        \"\"\"Multiplies grads by a constant *c*.\"\"\"                \n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is not None:\n",
    "                    p.grad.data.mul_(c)\n",
    "        \n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def rate(self, step = None):\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return 0 if not step else self.factor * get_rate(self.model_size, step, self.warmup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFJlkOMONsc6"
   },
   "source": [
    "## Scheduling Visualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "A135fwPCNrQs",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = NoamOpt(\n",
    "    model_size=arch_args.encoder_embed_dim, \n",
    "    factor=config.lr_factor, \n",
    "    warmup=config.lr_warmup, \n",
    "    optimizer=torch.optim.AdamW(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9, weight_decay=0.0001))\n",
    "plt.plot(np.arange(1, 100000), [optimizer.rate(i) for i in range(1, 100000)])\n",
    "plt.legend([f\"{optimizer.model_size}:{optimizer.warmup}\"])\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOR0g-cVO5ZO"
   },
   "source": [
    "# Training Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-0ZjbK3O8Iv"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "foal3xM1O404",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fairseq.data import iterators\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "def train_one_epoch(epoch_itr, model, task, criterion, optimizer, accum_steps=1):\n",
    "    itr = epoch_itr.next_epoch_itr(shuffle=True)\n",
    "    itr = iterators.GroupedIterator(itr, accum_steps) # gradient accumulation: update every accum_steps samples\n",
    "    \n",
    "    stats = {\"loss\": []}\n",
    "    scaler = GradScaler() # automatic mixed precision (amp) \n",
    "    \n",
    "    model.train()\n",
    "    progress = tqdm.tqdm(itr, desc=f\"train epoch {epoch_itr.epoch}\", leave=False)\n",
    "    for samples in progress:\n",
    "        model.zero_grad()\n",
    "        accum_loss = 0\n",
    "        sample_size = 0\n",
    "        # gradient accumulation: update every accum_steps samples\n",
    "        for i, sample in enumerate(samples):\n",
    "            if i == 1:\n",
    "                # emptying the CUDA cache after the first step can reduce the chance of OOM\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            sample = utils.move_to_cuda(sample, device=device)\n",
    "            target = sample[\"target\"]\n",
    "            sample_size_i = sample[\"ntokens\"]\n",
    "            sample_size += sample_size_i\n",
    "            \n",
    "            # mixed precision training\n",
    "            with autocast():\n",
    "                net_output = model.forward(**sample[\"net_input\"])\n",
    "                lprobs = F.log_softmax(net_output[0], -1)            \n",
    "                loss = criterion(lprobs.view(-1, lprobs.size(-1)), target.view(-1))\n",
    "                \n",
    "                # logging\n",
    "                accum_loss += loss.item()\n",
    "                # back-prop\n",
    "                scaler.scale(loss).backward()                \n",
    "        \n",
    "        scaler.unscale_(optimizer)\n",
    "        optimizer.multiply_grads(1 / (sample_size or 1.0)) # (sample_size or 1.0) handles the case of a zero gradient\n",
    "        gnorm = nn.utils.clip_grad_norm_(model.parameters(), config.clip_norm) # grad norm clipping prevents gradient exploding\n",
    "        \n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        # logging\n",
    "        loss_print = accum_loss/sample_size\n",
    "        stats[\"loss\"].append(loss_print)\n",
    "        progress.set_postfix(loss=loss_print)\n",
    "        if config.use_wandb:\n",
    "            wandb.log({\n",
    "                \"train/loss\": loss_print,\n",
    "                \"train/grad_norm\": gnorm.item(),\n",
    "                \"train/lr\": optimizer.rate(),\n",
    "                \"train/sample_size\": sample_size,\n",
    "            })\n",
    "        \n",
    "    loss_print = np.mean(stats[\"loss\"])\n",
    "    logger.info(f\"training loss: {loss_print:.4f}\")\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gt1lX3DRO_yU"
   },
   "source": [
    "## Validation & Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "2og80HYQPAKq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fairseq's beam search generator\n",
    "# given model and input seqeunce, produce translation hypotheses by beam search\n",
    "sequence_generator = task.build_generator([model], config)\n",
    "\n",
    "def decode(toks, dictionary):\n",
    "    # convert from Tensor to human readable sentence\n",
    "    s = dictionary.string(\n",
    "        toks.int().cpu(),\n",
    "        config.post_process,\n",
    "    )\n",
    "    return s if s else \"<unk>\"\n",
    "\n",
    "def inference_step(sample, model):\n",
    "    gen_out = sequence_generator.generate([model], sample)\n",
    "    srcs = []\n",
    "    hyps = []\n",
    "    refs = []\n",
    "    for i in range(len(gen_out)):\n",
    "        # for each sample, collect the input, hypothesis and reference, later be used to calculate BLEU\n",
    "        srcs.append(decode(\n",
    "            utils.strip_pad(sample[\"net_input\"][\"src_tokens\"][i], task.source_dictionary.pad()), \n",
    "            task.source_dictionary,\n",
    "        ))\n",
    "        hyps.append(decode(\n",
    "            gen_out[i][0][\"tokens\"], # 0 indicates using the top hypothesis in beam\n",
    "            task.target_dictionary,\n",
    "        ))\n",
    "        refs.append(decode(\n",
    "            utils.strip_pad(sample[\"target\"][i], task.target_dictionary.pad()), \n",
    "            task.target_dictionary,\n",
    "        ))\n",
    "    return srcs, hyps, refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "y1o7LeDkPDsd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import sacrebleu\n",
    "\n",
    "def validate(model, task, criterion, log_to_wandb=True):\n",
    "    logger.info('begin validation')\n",
    "    itr = load_data_iterator(task, \"valid\", 1, config.max_tokens, config.num_workers).next_epoch_itr(shuffle=False)\n",
    "    \n",
    "    stats = {\"loss\":[], \"bleu\": 0, \"srcs\":[], \"hyps\":[], \"refs\":[]}\n",
    "    srcs = []\n",
    "    hyps = []\n",
    "    refs = []\n",
    "    \n",
    "    model.eval()\n",
    "    progress = tqdm.tqdm(itr, desc=f\"validation\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for i, sample in enumerate(progress):\n",
    "            # validation loss\n",
    "            sample = utils.move_to_cuda(sample, device=device)\n",
    "            net_output = model.forward(**sample[\"net_input\"])\n",
    "\n",
    "            lprobs = F.log_softmax(net_output[0], -1)\n",
    "            target = sample[\"target\"]\n",
    "            sample_size = sample[\"ntokens\"]\n",
    "            loss = criterion(lprobs.view(-1, lprobs.size(-1)), target.view(-1)) / sample_size\n",
    "            progress.set_postfix(valid_loss=loss.item())\n",
    "            stats[\"loss\"].append(loss)\n",
    "            \n",
    "            # do inference\n",
    "            s, h, r = inference_step(sample, model)\n",
    "            srcs.extend(s)\n",
    "            hyps.extend(h)\n",
    "            refs.extend(r)\n",
    "            \n",
    "    tok = 'zh' if task.cfg.target_lang == 'zh' else '13a'\n",
    "    stats[\"loss\"] = torch.stack(stats[\"loss\"]).mean().item()\n",
    "    stats[\"bleu\"] = sacrebleu.corpus_bleu(hyps, [refs], tokenize=tok) # 計算BLEU score\n",
    "    stats[\"srcs\"] = srcs\n",
    "    stats[\"hyps\"] = hyps\n",
    "    stats[\"refs\"] = refs\n",
    "    \n",
    "    if config.use_wandb and log_to_wandb:\n",
    "        wandb.log({\n",
    "            \"valid/loss\": stats[\"loss\"],\n",
    "            \"valid/bleu\": stats[\"bleu\"].score,\n",
    "        }, commit=False)\n",
    "    \n",
    "    showid = np.random.randint(len(hyps))\n",
    "    logger.info(\"example source: \" + srcs[showid])\n",
    "    logger.info(\"example hypothesis: \" + hyps[showid])\n",
    "    logger.info(\"example reference: \" + refs[showid])\n",
    "    \n",
    "    # show bleu results\n",
    "    logger.info(f\"validation loss:\\t{stats['loss']:.4f}\")\n",
    "    logger.info(stats[\"bleu\"].format())\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1sRF6nd4PGEE"
   },
   "source": [
    "# Save and Load Model Weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "edBuLlkuPGr9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_and_save(model, task, criterion, optimizer, epoch, save=True):   \n",
    "    stats = validate(model, task, criterion)\n",
    "    bleu = stats['bleu']\n",
    "    loss = stats['loss']\n",
    "    if save:\n",
    "        # save epoch checkpoints\n",
    "        savedir = Path(config.savedir).absolute()\n",
    "        savedir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        check = {\n",
    "            \"model\": model.state_dict(),\n",
    "            \"stats\": {\"bleu\": bleu.score, \"loss\": loss},\n",
    "            \"optim\": {\"step\": optimizer._step}\n",
    "        }\n",
    "        torch.save(check, savedir/f\"checkpoint{epoch}.pt\")\n",
    "        shutil.copy(savedir/f\"checkpoint{epoch}.pt\", savedir/f\"checkpoint_last.pt\")\n",
    "        logger.info(f\"saved epoch checkpoint: {savedir}/checkpoint{epoch}.pt\")\n",
    "    \n",
    "        # save epoch samples\n",
    "        with open(savedir/f\"samples{epoch}.{config.source_lang}-{config.target_lang}.txt\", \"w\") as f:\n",
    "            for s, h in zip(stats[\"srcs\"], stats[\"hyps\"]):\n",
    "                f.write(f\"{s}\\t{h}\\n\")\n",
    "\n",
    "        # get best valid bleu    \n",
    "        if getattr(validate_and_save, \"best_bleu\", 0) < bleu.score:\n",
    "            validate_and_save.best_bleu = bleu.score\n",
    "            torch.save(check, savedir/f\"checkpoint_best.pt\")\n",
    "            \n",
    "        del_file = savedir / f\"checkpoint{epoch - config.keep_last_epochs}.pt\"\n",
    "        if del_file.exists():\n",
    "            del_file.unlink()\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def try_load_checkpoint(model, optimizer=None, name=None):\n",
    "    name = name if name else \"checkpoint_last.pt\"\n",
    "    checkpath = Path(config.savedir)/name\n",
    "    if checkpath.exists():\n",
    "        check = torch.load(checkpath)\n",
    "        model.load_state_dict(check[\"model\"])\n",
    "        stats = check[\"stats\"]\n",
    "        step = \"unknown\"\n",
    "        if optimizer != None:\n",
    "            optimizer._step = step = check[\"optim\"][\"step\"]\n",
    "        logger.info(f\"loaded checkpoint {checkpath}: step={step} loss={stats['loss']} bleu={stats['bleu']}\")\n",
    "        print(f\"loaded checkpoint {checkpath}: step={step} loss={stats['loss']} bleu={stats['bleu']}\")\n",
    "    else:\n",
    "        logger.info(f\"no checkpoints found at {checkpath}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyIFpibfPJ5u"
   },
   "source": [
    "# Main\n",
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "hu7RZbCUPKQr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.to(device=device)\n",
    "criterion = criterion.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "5xxlJxU2PeAo",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-06 23:46:20 | INFO | hw5.seq2seq | task: TranslationTask\n",
      "2024-01-06 23:46:20 | INFO | hw5.seq2seq | encoder: TransformerEncoder\n",
      "2024-01-06 23:46:20 | INFO | hw5.seq2seq | decoder: TransformerDecoder\n",
      "2024-01-06 23:46:20 | INFO | hw5.seq2seq | criterion: LabelSmoothedCrossEntropyCriterion\n",
      "2024-01-06 23:46:20 | INFO | hw5.seq2seq | optimizer: NoamOpt\n",
      "2024-01-06 23:46:20 | INFO | hw5.seq2seq | num. model params: 24,589,312 (num. trained: 24,589,312)\n",
      "2024-01-06 23:46:20 | INFO | hw5.seq2seq | max tokens per batch = 8192, accumulate steps = 2\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"task: {}\".format(task.__class__.__name__))\n",
    "logger.info(\"encoder: {}\".format(model.encoder.__class__.__name__))\n",
    "logger.info(\"decoder: {}\".format(model.decoder.__class__.__name__))\n",
    "logger.info(\"criterion: {}\".format(criterion.__class__.__name__))\n",
    "logger.info(\"optimizer: {}\".format(optimizer.__class__.__name__))\n",
    "logger.info(\n",
    "    \"num. model params: {:,} (num. trained: {:,})\".format(\n",
    "        sum(p.numel() for p in model.parameters()),\n",
    "        sum(p.numel() for p in model.parameters() if p.requires_grad),\n",
    "    )\n",
    ")\n",
    "logger.info(f\"max tokens per batch = {config.max_tokens}, accumulate steps = {config.accum_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "id": "MSPRqpQUPfaX",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-06 23:46:23 | INFO | hw5.seq2seq | no checkpoints found at checkpoints/transformer/checkpoint_last.pt!\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005771160125732422,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "train epoch 1",
       "rate": null,
       "total": 3296,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 1:   0%|          | 0/3296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-06 23:55:27 | INFO | hw5.seq2seq | training loss: 6.3910\n",
      "2024-01-06 23:55:27 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0051746368408203125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "validation",
       "rate": null,
       "total": 90,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-06 23:56:56 | INFO | hw5.seq2seq | example source: even very experienced photographers have many bad timing shots for this type of image .\n",
      "2024-01-06 23:56:56 | INFO | hw5.seq2seq | example hypothesis: 即使是非常经验的摄影师 , 有许多糟糕的时机在这种类型的图像中 。\n",
      "2024-01-06 23:56:56 | INFO | hw5.seq2seq | example reference: 就算资深摄影师在拍摄这种图片时也要经历很多次失败 。\n",
      "2024-01-06 23:56:56 | INFO | hw5.seq2seq | validation loss:\t4.7977\n",
      "2024-01-06 23:56:56 | INFO | hw5.seq2seq | BLEU = 16.81 57.1/29.0/15.7/9.1 (BP = 0.762 ratio = 0.787 hyp_len = 517978 ref_len = 658487)\n",
      "2024-01-06 23:56:56 | INFO | hw5.seq2seq | saved epoch checkpoint: /root/checkpoints/transformer/checkpoint1.pt\n",
      "2024-01-06 23:56:56 | INFO | hw5.seq2seq | end of epoch 1\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005626201629638672,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "train epoch 2",
       "rate": null,
       "total": 3296,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 2:   0%|          | 0/3296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 00:06:05 | INFO | hw5.seq2seq | training loss: 4.6568\n",
      "2024-01-07 00:06:05 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005400657653808594,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "validation",
       "rate": null,
       "total": 90,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 00:07:36 | INFO | hw5.seq2seq | example source: he served in the marine corps as an intelligence officer and deployed to afghanistan in 2003 , 2004 , and 2005 .\n",
      "2024-01-07 00:07:36 | INFO | hw5.seq2seq | example hypothesis: 他于2003年在海军陆战队服役 , 并于2003年部署到阿富汗 , 2004年 , 2005年和2005年 。\n",
      "2024-01-07 00:07:36 | INFO | hw5.seq2seq | example reference: 他是海军陆战队的情报官员 , 2003、2004和2005年随军队部署到阿富汗 。\n",
      "2024-01-07 00:07:36 | INFO | hw5.seq2seq | validation loss:\t4.3114\n",
      "2024-01-07 00:07:36 | INFO | hw5.seq2seq | BLEU = 21.92 59.4/32.2/18.6/11.4 (BP = 0.869 ratio = 0.877 hyp_len = 577221 ref_len = 658487)\n",
      "2024-01-07 00:07:36 | INFO | hw5.seq2seq | saved epoch checkpoint: /root/checkpoints/transformer/checkpoint2.pt\n",
      "2024-01-07 00:07:36 | INFO | hw5.seq2seq | end of epoch 2\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005261898040771484,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "train epoch 3",
       "rate": null,
       "total": 3296,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 3:   0%|          | 0/3296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 00:16:46 | INFO | hw5.seq2seq | training loss: 4.3539\n",
      "2024-01-07 00:16:46 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005442619323730469,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "validation",
       "rate": null,
       "total": 90,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 00:18:23 | INFO | hw5.seq2seq | example source: a woman with a wad of coca in her left cheek—a figurine from a sacrificial burial—is one of the rare surviving pieces of inca artifact .\n",
      "2024-01-07 00:18:23 | INFO | hw5.seq2seq | example hypothesis: 一个女人 , 她左脸颊上wad的coca , 一个女人从牺牲的墓葬中 , 是一个罕见幸存的印卡文物之一 。\n",
      "2024-01-07 00:18:23 | INFO | hw5.seq2seq | example reference: 一尊来自祭祀葬礼的女性雕像 , 她左边的面颊里还塞着一团古柯叶 。 它是少数幸存下来的印加手工艺品之一 。\n",
      "2024-01-07 00:18:23 | INFO | hw5.seq2seq | validation loss:\t4.1616\n",
      "2024-01-07 00:18:23 | INFO | hw5.seq2seq | BLEU = 23.73 59.6/32.9/19.4/12.1 (BP = 0.911 ratio = 0.915 hyp_len = 602429 ref_len = 658487)\n",
      "2024-01-07 00:18:23 | INFO | hw5.seq2seq | saved epoch checkpoint: /root/checkpoints/transformer/checkpoint3.pt\n",
      "2024-01-07 00:18:24 | INFO | hw5.seq2seq | end of epoch 3\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005039215087890625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "train epoch 4",
       "rate": null,
       "total": 3296,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 4:   0%|          | 0/3296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 00:27:28 | INFO | hw5.seq2seq | training loss: 4.2346\n",
      "2024-01-07 00:27:28 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005446195602416992,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "validation",
       "rate": null,
       "total": 90,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 00:28:59 | INFO | hw5.seq2seq | example source: the mathematical model for aircraft engine , heat exchanger , duct , venturi , valve and other components in aircraft environment control system is described in this paper .\n",
      "2024-01-07 00:28:59 | INFO | hw5.seq2seq | example hypothesis: 介绍了飞机发动机、换热器、管道、阀门等部件在飞机环境控制系统的数学模型 。\n",
      "2024-01-07 00:28:59 | INFO | hw5.seq2seq | example reference: 介绍了飞机环境控制系统中发动机引气、热交换器、管道、文氏管以及阀门等部件的数学模型 。\n",
      "2024-01-07 00:28:59 | INFO | hw5.seq2seq | validation loss:\t4.0912\n",
      "2024-01-07 00:28:59 | INFO | hw5.seq2seq | BLEU = 24.11 61.2/34.4/20.5/13.0 (BP = 0.881 ratio = 0.887 hyp_len = 584361 ref_len = 658487)\n",
      "2024-01-07 00:28:59 | INFO | hw5.seq2seq | saved epoch checkpoint: /root/checkpoints/transformer/checkpoint4.pt\n",
      "2024-01-07 00:28:59 | INFO | hw5.seq2seq | end of epoch 4\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005043983459472656,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "train epoch 5",
       "rate": null,
       "total": 3296,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 5:   0%|          | 0/3296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 00:38:02 | INFO | hw5.seq2seq | training loss: 4.1676\n",
      "2024-01-07 00:38:02 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00534820556640625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "validation",
       "rate": null,
       "total": 90,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 00:39:34 | INFO | hw5.seq2seq | example source: its survival has been threatened by the appearance of another plant , an invasive species called european beachgrass .\n",
      "2024-01-07 00:39:34 | INFO | hw5.seq2seq | example hypothesis: 它的生存受到另一个植物的威胁 , 一种叫做欧洲海滩草的入侵物种 。\n",
      "2024-01-07 00:39:34 | INFO | hw5.seq2seq | example reference: 它的生存由于另一个植物的出现而受到了威胁 , 这是个带有侵略性的物种被称作欧洲喜沙草属 。\n",
      "2024-01-07 00:39:34 | INFO | hw5.seq2seq | validation loss:\t4.0358\n",
      "2024-01-07 00:39:34 | INFO | hw5.seq2seq | BLEU = 24.84 60.6/34.2/20.5/13.1 (BP = 0.910 ratio = 0.914 hyp_len = 601951 ref_len = 658487)\n",
      "2024-01-07 00:39:34 | INFO | hw5.seq2seq | saved epoch checkpoint: /root/checkpoints/transformer/checkpoint5.pt\n",
      "2024-01-07 00:39:34 | INFO | hw5.seq2seq | end of epoch 5\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004981517791748047,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "train epoch 6",
       "rate": null,
       "total": 3296,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 6:   0%|          | 0/3296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 00:48:40 | INFO | hw5.seq2seq | training loss: 4.1232\n",
      "2024-01-07 00:48:40 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005337238311767578,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "validation",
       "rate": null,
       "total": 90,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 00:50:11 | INFO | hw5.seq2seq | example source: look at all the data that goes into protein folding .\n",
      "2024-01-07 00:50:11 | INFO | hw5.seq2seq | example hypothesis: 看看蛋白质折叠的所有数据 。\n",
      "2024-01-07 00:50:11 | INFO | hw5.seq2seq | example reference: 看看所有进入蛋白质折叠【译注】的数据 。\n",
      "2024-01-07 00:50:11 | INFO | hw5.seq2seq | validation loss:\t4.0080\n",
      "2024-01-07 00:50:11 | INFO | hw5.seq2seq | BLEU = 24.65 62.2/35.4/21.3/13.6 (BP = 0.872 ratio = 0.879 hyp_len = 578986 ref_len = 658487)\n",
      "2024-01-07 00:50:11 | INFO | hw5.seq2seq | saved epoch checkpoint: /root/checkpoints/transformer/checkpoint6.pt\n",
      "2024-01-07 00:50:11 | INFO | hw5.seq2seq | end of epoch 6\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004908561706542969,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "train epoch 7",
       "rate": null,
       "total": 3296,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 7:   0%|          | 0/3296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 00:59:18 | INFO | hw5.seq2seq | training loss: 4.0915\n",
      "2024-01-07 00:59:18 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00542759895324707,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "validation",
       "rate": null,
       "total": 90,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 01:00:47 | INFO | hw5.seq2seq | example source: if i wear this dress , then john might ask me out !\n",
      "2024-01-07 01:00:47 | INFO | hw5.seq2seq | example hypothesis: 如果我穿这件衣服 , 那么约翰可能会问我出去 !\n",
      "2024-01-07 01:00:47 | INFO | hw5.seq2seq | example reference: 她穿那件洋装的那天 , 约翰会约她出去 。\n",
      "2024-01-07 01:00:47 | INFO | hw5.seq2seq | validation loss:\t3.9823\n",
      "2024-01-07 01:00:47 | INFO | hw5.seq2seq | BLEU = 25.25 61.4/34.9/21.1/13.5 (BP = 0.905 ratio = 0.909 hyp_len = 598556 ref_len = 658487)\n",
      "2024-01-07 01:00:48 | INFO | hw5.seq2seq | saved epoch checkpoint: /root/checkpoints/transformer/checkpoint7.pt\n",
      "2024-01-07 01:00:48 | INFO | hw5.seq2seq | end of epoch 7\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0052874088287353516,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "train epoch 8",
       "rate": null,
       "total": 3296,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 8:   0%|          | 0/3296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 01:09:54 | INFO | hw5.seq2seq | training loss: 4.0666\n",
      "2024-01-07 01:09:54 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0053560733795166016,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "validation",
       "rate": null,
       "total": 90,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 01:11:24 | INFO | hw5.seq2seq | example source: the solvent effects on the nonlinear optical properties of para nitroaniline molecule are studied on the base of time dependent density functional theory .\n",
      "2024-01-07 01:11:24 | INFO | hw5.seq2seq | example hypothesis: 在时间依赖密度函数理论的基础上 , 研究了溶剂对亚硝基苯胺分子的非线性光学性质的影响 。\n",
      "2024-01-07 01:11:24 | INFO | hw5.seq2seq | example reference: 在含时密度泛函理论水平上研究了溶剂对硝基苯胺分子非线性光学性质的影响 。\n",
      "2024-01-07 01:11:24 | INFO | hw5.seq2seq | validation loss:\t3.9684\n",
      "2024-01-07 01:11:24 | INFO | hw5.seq2seq | BLEU = 25.28 62.3/35.6/21.6/13.9 (BP = 0.886 ratio = 0.892 hyp_len = 587366 ref_len = 658487)\n",
      "2024-01-07 01:11:24 | INFO | hw5.seq2seq | saved epoch checkpoint: /root/checkpoints/transformer/checkpoint8.pt\n",
      "2024-01-07 01:11:24 | INFO | hw5.seq2seq | end of epoch 8\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005143404006958008,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "train epoch 9",
       "rate": null,
       "total": 3296,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 9:   0%|          | 0/3296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 01:20:29 | INFO | hw5.seq2seq | training loss: 4.0474\n",
      "2024-01-07 01:20:29 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005509376525878906,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "validation",
       "rate": null,
       "total": 90,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 01:21:58 | INFO | hw5.seq2seq | example source: the warm , humid climate makes hainan a bounty of tropical crops — the island is an important producer of pineapples , coconuts , mangoes , sugar cane , coffee and rubber trees .\n",
      "2024-01-07 01:21:58 | INFO | hw5.seq2seq | example hypothesis: 温暖潮湿的气候使海南成为热带作物的盛宴 , 岛是菠萝、椰子、芒果、甘蔗、咖啡和橡胶树的重要生产地 。\n",
      "2024-01-07 01:21:58 | INFO | hw5.seq2seq | example reference: 温暖湿润的气候使海南的热带植物繁茂海南岛是菠萝、可可豆、芒果、甘蔗、咖啡和橡胶的重要产地 。\n",
      "2024-01-07 01:21:58 | INFO | hw5.seq2seq | validation loss:\t3.9575\n",
      "2024-01-07 01:21:58 | INFO | hw5.seq2seq | BLEU = 25.01 63.0/36.1/22.0/14.2 (BP = 0.861 ratio = 0.870 hyp_len = 572644 ref_len = 658487)\n",
      "2024-01-07 01:21:58 | INFO | hw5.seq2seq | saved epoch checkpoint: /root/checkpoints/transformer/checkpoint9.pt\n",
      "2024-01-07 01:21:58 | INFO | hw5.seq2seq | end of epoch 9\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004976511001586914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "train epoch 10",
       "rate": null,
       "total": 3296,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 10:   0%|          | 0/3296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 01:31:06 | INFO | hw5.seq2seq | training loss: 4.0316\n",
      "2024-01-07 01:31:06 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006043910980224609,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "validation",
       "rate": null,
       "total": 90,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 01:32:37 | INFO | hw5.seq2seq | example source: you can use different approaches to introduce your new webservice to your visitors .\n",
      "2024-01-07 01:32:37 | INFO | hw5.seq2seq | example hypothesis: 您可以使用不同的方法将新web服务引入到您的访问者 。\n",
      "2024-01-07 01:32:37 | INFO | hw5.seq2seq | example reference: 你可以通过不同的途径向你的访问者介绍网站服务 。\n",
      "2024-01-07 01:32:37 | INFO | hw5.seq2seq | validation loss:\t3.9417\n",
      "2024-01-07 01:32:37 | INFO | hw5.seq2seq | BLEU = 25.45 62.0/35.4/21.5/13.8 (BP = 0.895 ratio = 0.900 hyp_len = 592590 ref_len = 658487)\n",
      "2024-01-07 01:32:37 | INFO | hw5.seq2seq | saved epoch checkpoint: /root/checkpoints/transformer/checkpoint10.pt\n",
      "2024-01-07 01:32:38 | INFO | hw5.seq2seq | end of epoch 10\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005106925964355469,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "train epoch 11",
       "rate": null,
       "total": 3296,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 11:   0%|          | 0/3296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 01:41:42 | INFO | hw5.seq2seq | training loss: 4.0174\n",
      "2024-01-07 01:41:42 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005651950836181641,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "validation",
       "rate": null,
       "total": 90,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 01:43:10 | INFO | hw5.seq2seq | example source: it is a dim sum palace in the \" lard cake \" on the basis of the restructuring .\n",
      "2024-01-07 01:43:10 | INFO | hw5.seq2seq | example hypothesis: 在重组的基础上 , 在 \" 拉德蛋糕 \" 中 , 它是一座昏暗的宫殿 。\n",
      "2024-01-07 01:43:10 | INFO | hw5.seq2seq | example reference: 它是在宫廷点心 \" 猪油饽饽 \" 的基础上改制的 。\n",
      "2024-01-07 01:43:10 | INFO | hw5.seq2seq | validation loss:\t3.9375\n",
      "2024-01-07 01:43:10 | INFO | hw5.seq2seq | BLEU = 25.58 62.6/36.0/22.0/14.2 (BP = 0.883 ratio = 0.889 hyp_len = 585452 ref_len = 658487)\n",
      "2024-01-07 01:43:10 | INFO | hw5.seq2seq | saved epoch checkpoint: /root/checkpoints/transformer/checkpoint11.pt\n",
      "2024-01-07 01:43:10 | INFO | hw5.seq2seq | end of epoch 11\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0050814151763916016,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "train epoch 12",
       "rate": null,
       "total": 3296,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 12:   0%|          | 0/3296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 01:52:16 | INFO | hw5.seq2seq | training loss: 4.0056\n",
      "2024-01-07 01:52:16 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005540132522583008,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "validation",
       "rate": null,
       "total": 90,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 01:53:45 | INFO | hw5.seq2seq | example source: how much do you know about the region of china that will host our first preseason game of 2011 ? here's 5 things you probably didn't know about guangdong...\n",
      "2024-01-07 01:53:45 | INFO | hw5.seq2seq | example hypothesis: 你们对2011年第一季季前赛的中国地区了解了多少 ? 这里有5件事你可能不知道广东...\n",
      "2024-01-07 01:53:45 | INFO | hw5.seq2seq | example reference: 你对这次举办我们2011年第一场季前赛的中国城市了解多少 ? 下面是5件关于广东你可能不知道的事...\n",
      "2024-01-07 01:53:45 | INFO | hw5.seq2seq | validation loss:\t3.9251\n",
      "2024-01-07 01:53:45 | INFO | hw5.seq2seq | BLEU = 25.73 62.5/36.0/21.9/14.2 (BP = 0.890 ratio = 0.895 hyp_len = 589620 ref_len = 658487)\n",
      "2024-01-07 01:53:45 | INFO | hw5.seq2seq | saved epoch checkpoint: /root/checkpoints/transformer/checkpoint12.pt\n",
      "2024-01-07 01:53:45 | INFO | hw5.seq2seq | end of epoch 12\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004909992218017578,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "train epoch 13",
       "rate": null,
       "total": 3296,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89dad299ce9c4770934f4c8871c097a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 13:   0%|          | 0/3296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 02:02:57 | INFO | hw5.seq2seq | training loss: 3.9961\n",
      "2024-01-07 02:02:57 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005350589752197266,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "validation",
       "rate": null,
       "total": 90,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27785bb2bdcb473a8921a9e6c91066bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 02:04:27 | INFO | hw5.seq2seq | example source: rachel: of course ! why don't we go to mcdonald's ? we've always wanted to taste a hamburger .\n",
      "2024-01-07 02:04:27 | INFO | hw5.seq2seq | example hypothesis: 瑞秋:当然 ! 我们为什么不去麦当劳呢 ? 我们总是想尝汉堡 。\n",
      "2024-01-07 02:04:27 | INFO | hw5.seq2seq | example reference: 拉结:当然有 ! 为什麽我们不去麦当劳速食店 ? 我们总是想尝尝汉堡 。\n",
      "2024-01-07 02:04:27 | INFO | hw5.seq2seq | validation loss:\t3.9105\n",
      "2024-01-07 02:04:27 | INFO | hw5.seq2seq | BLEU = 25.82 62.2/35.7/21.8/14.1 (BP = 0.899 ratio = 0.903 hyp_len = 594855 ref_len = 658487)\n",
      "2024-01-07 02:04:27 | INFO | hw5.seq2seq | saved epoch checkpoint: /root/checkpoints/transformer/checkpoint13.pt\n",
      "2024-01-07 02:04:27 | INFO | hw5.seq2seq | end of epoch 13\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005383014678955078,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "train epoch 14",
       "rate": null,
       "total": 3296,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca559a3a1bc1428392e02693eb4b2eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 14:   0%|          | 0/3296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 02:13:34 | INFO | hw5.seq2seq | training loss: 3.9875\n",
      "2024-01-07 02:13:34 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005464792251586914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "validation",
       "rate": null,
       "total": 90,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 02:15:02 | INFO | hw5.seq2seq | example source: including version control and workspace management , defect and change management , software build , deploy and release , reflecting as chapter three scm course crm course and chapter four daily building .\n",
      "2024-01-07 02:15:02 | INFO | hw5.seq2seq | example hypothesis: 包括版本控制和工作空间管理 , 缺陷和变更管理 , 软件构建 , 部署和发布 , 作为第三章scm课程crm课程和第四章的日常构建 。\n",
      "2024-01-07 02:15:02 | INFO | hw5.seq2seq | example reference: 包括版本管理和工作空间管理、缺陷跟踪和变更管理、软件构造部署和发布过程 , 在论文中体现为第三章scm过程、crm过程和第四章日构建 。\n",
      "2024-01-07 02:15:02 | INFO | hw5.seq2seq | validation loss:\t3.9115\n",
      "2024-01-07 02:15:02 | INFO | hw5.seq2seq | BLEU = 25.55 63.1/36.4/22.4/14.5 (BP = 0.869 ratio = 0.877 hyp_len = 577645 ref_len = 658487)\n",
      "2024-01-07 02:15:02 | INFO | hw5.seq2seq | saved epoch checkpoint: /root/checkpoints/transformer/checkpoint14.pt\n",
      "2024-01-07 02:15:02 | INFO | hw5.seq2seq | end of epoch 14\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004969358444213867,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "train epoch 15",
       "rate": null,
       "total": 3296,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07103fc695cb4ed1bb6a5c3a5c91a121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 15:   0%|          | 0/3296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 02:55:50 | INFO | hw5.seq2seq | training loss: 3.9602\n",
      "2024-01-07 02:55:50 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005494832992553711,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "validation",
       "rate": null,
       "total": 90,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 02:57:17 | INFO | hw5.seq2seq | example source: pointing to the property of photoconductive multiunit infrared detector , an automatic testing system for uniformity of infrared detector is developed .\n",
      "2024-01-07 02:57:17 | INFO | hw5.seq2seq | example hypothesis: 针对光电导多单元红外探测器的性能 , 研制了红外探测器均匀性自动检测系统 。\n",
      "2024-01-07 02:57:17 | INFO | hw5.seq2seq | example reference: 针对光导型多元红外探测器特性 , 研制了红外探测器均匀性自动化测试系统 。\n",
      "2024-01-07 02:57:17 | INFO | hw5.seq2seq | validation loss:\t3.8959\n",
      "2024-01-07 02:57:17 | INFO | hw5.seq2seq | BLEU = 25.93 63.3/36.7/22.5/14.6 (BP = 0.877 ratio = 0.884 hyp_len = 582032 ref_len = 658487)\n",
      "2024-01-07 02:57:18 | INFO | hw5.seq2seq | saved epoch checkpoint: /root/checkpoints/transformer/checkpoint18.pt\n",
      "2024-01-07 02:57:18 | INFO | hw5.seq2seq | end of epoch 18\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0049457550048828125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "train epoch 19",
       "rate": null,
       "total": 3296,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 19:   0%|          | 0/3296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 03:06:27 | INFO | hw5.seq2seq | training loss: 3.9540\n",
      "2024-01-07 03:06:27 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0055675506591796875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "validation",
       "rate": null,
       "total": 90,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 03:07:59 | INFO | hw5.seq2seq | example source: both for christians and nonchristian often , so for example , you have the familiar birth story .\n",
      "2024-01-07 03:07:59 | INFO | hw5.seq2seq | example hypothesis: 对于基督徒和非基督教都经常 , 例如 , 你有一个熟悉的出生故事 。\n",
      "2024-01-07 03:07:59 | INFO | hw5.seq2seq | example reference: 不管是否基督教徒 , 比方说 , 这个人们熟知的诞生故事 。\n",
      "2024-01-07 03:07:59 | INFO | hw5.seq2seq | validation loss:\t3.8910\n",
      "2024-01-07 03:07:59 | INFO | hw5.seq2seq | BLEU = 25.96 63.3/36.7/22.6/14.7 (BP = 0.877 ratio = 0.884 hyp_len = 581862 ref_len = 658487)\n",
      "2024-01-07 03:07:59 | INFO | hw5.seq2seq | saved epoch checkpoint: /root/checkpoints/transformer/checkpoint19.pt\n",
      "2024-01-07 03:07:59 | INFO | hw5.seq2seq | end of epoch 19\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0055272579193115234,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "train epoch 20",
       "rate": null,
       "total": 3296,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 20:   0%|          | 0/3296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 03:16:58 | INFO | hw5.seq2seq | training loss: 3.9500\n",
      "2024-01-07 03:16:58 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005646944046020508,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "validation",
       "rate": null,
       "total": 90,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 03:18:27 | INFO | hw5.seq2seq | example source: during physical exercise , please keep quiet , no hubbub and playing are allowed .\n",
      "2024-01-07 03:18:27 | INFO | hw5.seq2seq | example hypothesis: 在体育锻炼时 , 请保持安静 , 不允许哈布布和打球 。\n",
      "2024-01-07 03:18:27 | INFO | hw5.seq2seq | example reference: 运动过程中请勿大声喧哗 , 嬉戏、打闹 。\n",
      "2024-01-07 03:18:27 | INFO | hw5.seq2seq | validation loss:\t3.8814\n",
      "2024-01-07 03:18:27 | INFO | hw5.seq2seq | BLEU = 26.25 62.9/36.5/22.4/14.6 (BP = 0.891 ratio = 0.897 hyp_len = 590492 ref_len = 658487)\n",
      "2024-01-07 03:18:27 | INFO | hw5.seq2seq | saved epoch checkpoint: /root/checkpoints/transformer/checkpoint20.pt\n",
      "2024-01-07 03:18:28 | INFO | hw5.seq2seq | end of epoch 20\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00514531135559082,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "train epoch 21",
       "rate": null,
       "total": 3296,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 21:   0%|          | 0/3296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 03:27:26 | INFO | hw5.seq2seq | training loss: 3.9446\n",
      "2024-01-07 03:27:26 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005655050277709961,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "validation",
       "rate": null,
       "total": 90,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 03:28:55 | INFO | hw5.seq2seq | example source: lol . the chinese square dance has spread to other countries .\n",
      "2024-01-07 03:28:55 | INFO | hw5.seq2seq | example hypothesis: 中国广场舞蹈向其他国家传播 。\n",
      "2024-01-07 03:28:55 | INFO | hw5.seq2seq | example reference: 中国的广场舞已经传到了全世界每一个角落了 。\n",
      "2024-01-07 03:28:55 | INFO | hw5.seq2seq | validation loss:\t3.8784\n",
      "2024-01-07 03:28:55 | INFO | hw5.seq2seq | BLEU = 26.13 63.1/36.6/22.5/14.6 (BP = 0.886 ratio = 0.892 hyp_len = 587284 ref_len = 658487)\n",
      "2024-01-07 03:28:55 | INFO | hw5.seq2seq | saved epoch checkpoint: /root/checkpoints/transformer/checkpoint21.pt\n",
      "2024-01-07 03:28:55 | INFO | hw5.seq2seq | end of epoch 21\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0064737796783447266,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "train epoch 22",
       "rate": null,
       "total": 3296,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 22:   0%|          | 0/3296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 03:38:00 | INFO | hw5.seq2seq | training loss: 3.9409\n",
      "2024-01-07 03:38:00 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006268739700317383,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "validation",
       "rate": null,
       "total": 90,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 03:39:29 | INFO | hw5.seq2seq | example source: according to the ngdc sun spot data , the relationship between the sun spots and earthquakes in the world is analyzed .\n",
      "2024-01-07 03:39:29 | INFO | hw5.seq2seq | example hypothesis: 根据ngdc太阳点数据 , 分析了太阳点与地震的关系 。\n",
      "2024-01-07 03:39:29 | INFO | hw5.seq2seq | example reference: 根据ngdc提供的太阳黑子资料 , 分析了太阳黑子活动与地球上巨震活动的关系 。\n",
      "2024-01-07 03:39:29 | INFO | hw5.seq2seq | validation loss:\t3.8787\n",
      "2024-01-07 03:39:29 | INFO | hw5.seq2seq | BLEU = 26.09 63.2/36.7/22.6/14.7 (BP = 0.880 ratio = 0.887 hyp_len = 583797 ref_len = 658487)\n",
      "2024-01-07 03:39:30 | INFO | hw5.seq2seq | saved epoch checkpoint: /root/checkpoints/transformer/checkpoint22.pt\n",
      "2024-01-07 03:39:30 | INFO | hw5.seq2seq | end of epoch 22\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005144834518432617,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "train epoch 23",
       "rate": null,
       "total": 3296,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 23:   0%|          | 0/3296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 03:48:42 | INFO | hw5.seq2seq | training loss: 3.9367\n",
      "2024-01-07 03:48:42 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0063283443450927734,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "validation",
       "rate": null,
       "total": 90,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 03:50:26 | INFO | hw5.seq2seq | example source: he remained a long time thus .\n",
      "2024-01-07 03:50:26 | INFO | hw5.seq2seq | example hypothesis: 他就这样呆了很长一段时间 。\n",
      "2024-01-07 03:50:26 | INFO | hw5.seq2seq | example reference: 他这样呆了许久 。\n",
      "2024-01-07 03:50:26 | INFO | hw5.seq2seq | validation loss:\t3.8662\n",
      "2024-01-07 03:50:26 | INFO | hw5.seq2seq | BLEU = 26.25 62.6/36.2/22.2/14.4 (BP = 0.899 ratio = 0.904 hyp_len = 595022 ref_len = 658487)\n",
      "2024-01-07 03:50:26 | INFO | hw5.seq2seq | saved epoch checkpoint: /root/checkpoints/transformer/checkpoint23.pt\n",
      "2024-01-07 03:50:26 | INFO | hw5.seq2seq | end of epoch 23\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00518345832824707,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "train epoch 24",
       "rate": null,
       "total": 3296,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 24:   0%|          | 0/3296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 03:59:30 | INFO | hw5.seq2seq | training loss: 3.9327\n",
      "2024-01-07 03:59:30 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005520820617675781,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "validation",
       "rate": null,
       "total": 90,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 04:01:00 | INFO | hw5.seq2seq | example source: now you have gone with the wind , leaving only the snow in my memory .\n",
      "2024-01-07 04:01:00 | INFO | hw5.seq2seq | example hypothesis: 现在你带着风走了 , 只留下积雪在我的记忆里 。\n",
      "2024-01-07 04:01:00 | INFO | hw5.seq2seq | example reference: 梅园不复 , 而你也早已随风而去 。\n",
      "2024-01-07 04:01:00 | INFO | hw5.seq2seq | validation loss:\t3.8630\n",
      "2024-01-07 04:01:00 | INFO | hw5.seq2seq | BLEU = 26.44 62.7/36.3/22.4/14.6 (BP = 0.900 ratio = 0.905 hyp_len = 595655 ref_len = 658487)\n",
      "2024-01-07 04:01:00 | INFO | hw5.seq2seq | saved epoch checkpoint: /root/checkpoints/transformer/checkpoint24.pt\n",
      "2024-01-07 04:01:00 | INFO | hw5.seq2seq | end of epoch 24\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005107879638671875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "train epoch 25",
       "rate": null,
       "total": 3296,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 25:   0%|          | 0/3296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 04:10:03 | INFO | hw5.seq2seq | training loss: 3.9298\n",
      "2024-01-07 04:10:03 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00546717643737793,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "validation",
       "rate": null,
       "total": 90,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 04:11:30 | INFO | hw5.seq2seq | example source: a new design of open source oilfree journal bearings was tested for performance parameters of load capacity and power loss .\n",
      "2024-01-07 04:11:30 | INFO | hw5.seq2seq | example hypothesis: 对开放源油无油轴承进行了性能参数测试 。\n",
      "2024-01-07 04:11:30 | INFO | hw5.seq2seq | example reference: 在轴承系统的设计与分析中 , 精确估算负载量、摩擦力、偏心角及侧向流率等参数是相当重要的 。\n",
      "2024-01-07 04:11:30 | INFO | hw5.seq2seq | validation loss:\t3.8806\n",
      "2024-01-07 04:11:30 | INFO | hw5.seq2seq | BLEU = 25.57 64.0/37.3/23.0/15.0 (BP = 0.850 ratio = 0.860 hyp_len = 566212 ref_len = 658487)\n",
      "2024-01-07 04:11:30 | INFO | hw5.seq2seq | saved epoch checkpoint: /root/checkpoints/transformer/checkpoint25.pt\n",
      "2024-01-07 04:11:30 | INFO | hw5.seq2seq | end of epoch 25\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0053195953369140625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "train epoch 26",
       "rate": null,
       "total": 3296,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 26:   0%|          | 0/3296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 04:20:38 | INFO | hw5.seq2seq | training loss: 3.9265\n",
      "2024-01-07 04:20:38 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0058710575103759766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "validation",
       "rate": null,
       "total": 90,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 04:22:30 | INFO | hw5.seq2seq | example source: wile charles was in prison ; sydney carton had also arrived in paris .\n",
      "2024-01-07 04:22:30 | INFO | hw5.seq2seq | example hypothesis: 威尔查尔斯在监狱里 , 悉尼卡顿也来到了巴黎 。\n",
      "2024-01-07 04:22:30 | INFO | hw5.seq2seq | example reference: 查尔斯坐牢的时候 , 悉尼·卡尔登也到巴黎来了 。\n",
      "2024-01-07 04:22:30 | INFO | hw5.seq2seq | validation loss:\t3.8665\n",
      "2024-01-07 04:22:30 | INFO | hw5.seq2seq | BLEU = 26.05 63.5/36.9/22.7/14.8 (BP = 0.876 ratio = 0.883 hyp_len = 581242 ref_len = 658487)\n",
      "2024-01-07 04:22:30 | INFO | hw5.seq2seq | saved epoch checkpoint: /root/checkpoints/transformer/checkpoint26.pt\n",
      "2024-01-07 04:22:30 | INFO | hw5.seq2seq | end of epoch 26\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005075693130493164,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "train epoch 27",
       "rate": null,
       "total": 3296,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 27:   0%|          | 0/3296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 04:31:34 | INFO | hw5.seq2seq | training loss: 3.9229\n",
      "2024-01-07 04:31:34 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005574703216552734,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "validation",
       "rate": null,
       "total": 90,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 04:33:05 | INFO | hw5.seq2seq | example source: if you are going to lead this industry , you must push the envelope .\n",
      "2024-01-07 04:33:05 | INFO | hw5.seq2seq | example hypothesis: 如果你要领导这个行业 , 你必须推信封 。\n",
      "2024-01-07 04:33:05 | INFO | hw5.seq2seq | example reference: 如果你想在这个行业执牛耳的话 , 你就得努力创新 。\n",
      "2024-01-07 04:33:05 | INFO | hw5.seq2seq | validation loss:\t3.8440\n",
      "2024-01-07 04:33:05 | INFO | hw5.seq2seq | BLEU = 26.34 61.9/35.8/22.0/14.3 (BP = 0.912 ratio = 0.916 hyp_len = 602860 ref_len = 658487)\n",
      "2024-01-07 04:33:05 | INFO | hw5.seq2seq | saved epoch checkpoint: /root/checkpoints/transformer/checkpoint27.pt\n",
      "2024-01-07 04:33:05 | INFO | hw5.seq2seq | end of epoch 27\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005126237869262695,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "train epoch 28",
       "rate": null,
       "total": 3296,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 28:   0%|          | 0/3296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 04:42:03 | INFO | hw5.seq2seq | training loss: 3.9205\n",
      "2024-01-07 04:42:03 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00588226318359375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "validation",
       "rate": null,
       "total": 90,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 04:43:32 | INFO | hw5.seq2seq | example source: when my friends were watching fireworks performance i was taking the ielts mock test alone .\n",
      "2024-01-07 04:43:32 | INFO | hw5.seq2seq | example hypothesis: 当我的朋友们观看烟花表演时 , 我独自去参加ielts的模拟测试 。\n",
      "2024-01-07 04:43:32 | INFO | hw5.seq2seq | example reference: 当大家欣赏焰火表演的时候 , 自己在空空的教室中做雅思模拟题 。\n",
      "2024-01-07 04:43:32 | INFO | hw5.seq2seq | validation loss:\t3.8499\n",
      "2024-01-07 04:43:32 | INFO | hw5.seq2seq | BLEU = 26.38 62.7/36.4/22.4/14.6 (BP = 0.899 ratio = 0.903 hyp_len = 594935 ref_len = 658487)\n",
      "2024-01-07 04:43:32 | INFO | hw5.seq2seq | saved epoch checkpoint: /root/checkpoints/transformer/checkpoint28.pt\n",
      "2024-01-07 04:43:32 | INFO | hw5.seq2seq | end of epoch 28\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004987239837646484,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "train epoch 29",
       "rate": null,
       "total": 3296,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 29:   0%|          | 0/3296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 04:52:31 | INFO | hw5.seq2seq | training loss: 3.9177\n",
      "2024-01-07 04:52:31 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005353212356567383,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "validation",
       "rate": null,
       "total": 90,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 04:54:22 | INFO | hw5.seq2seq | example source: each course in the school of fine art ; painting , photography , printmaking and sculpture , represents an autonomous subject area , that has its own vision and identity .\n",
      "2024-01-07 04:54:22 | INFO | hw5.seq2seq | example hypothesis: 美术学院的每一门课程 , 绘画 , 摄影 , 印刷和雕塑 , 代表一个自治的学科领域 , 拥有自己的视觉和身份 。\n",
      "2024-01-07 04:54:22 | INFO | hw5.seq2seq | example reference: 美术学院的每一门课程 , 绘画、摄影、板画和雕塑 , 都是一个独立的领域 , 有着各自的形式和特点 。\n",
      "2024-01-07 04:54:22 | INFO | hw5.seq2seq | validation loss:\t3.8460\n",
      "2024-01-07 04:54:22 | INFO | hw5.seq2seq | BLEU = 26.44 62.7/36.4/22.4/14.6 (BP = 0.900 ratio = 0.904 hyp_len = 595527 ref_len = 658487)\n",
      "2024-01-07 04:54:22 | INFO | hw5.seq2seq | saved epoch checkpoint: /root/checkpoints/transformer/checkpoint29.pt\n",
      "2024-01-07 04:54:22 | INFO | hw5.seq2seq | end of epoch 29\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005039691925048828,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "train epoch 30",
       "rate": null,
       "total": 3296,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 30:   0%|          | 0/3296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 05:03:23 | INFO | hw5.seq2seq | training loss: 3.9150\n",
      "2024-01-07 05:03:23 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005503177642822266,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "validation",
       "rate": null,
       "total": 90,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 05:04:50 | INFO | hw5.seq2seq | example source: then we have their new theme .\n",
      "2024-01-07 05:04:50 | INFO | hw5.seq2seq | example hypothesis: 然后我们有他们新的主题 。\n",
      "2024-01-07 05:04:50 | INFO | hw5.seq2seq | example reference: 然后我们还有了新主题 。\n",
      "2024-01-07 05:04:50 | INFO | hw5.seq2seq | validation loss:\t3.8700\n",
      "2024-01-07 05:04:50 | INFO | hw5.seq2seq | BLEU = 26.15 63.8/37.1/22.9/15.0 (BP = 0.870 ratio = 0.878 hyp_len = 578027 ref_len = 658487)\n",
      "2024-01-07 05:04:50 | INFO | hw5.seq2seq | saved epoch checkpoint: /root/checkpoints/transformer/checkpoint30.pt\n",
      "2024-01-07 05:04:50 | INFO | hw5.seq2seq | end of epoch 30\n"
     ]
    }
   ],
   "source": [
    "epoch_itr = load_data_iterator(task, \"train\", config.start_epoch, config.max_tokens, config.num_workers)\n",
    "try_load_checkpoint(model, optimizer, name=config.resume)\n",
    "while epoch_itr.next_epoch_idx <= config.max_epoch:\n",
    "    # train for one epoch\n",
    "    train_one_epoch(epoch_itr, model, task, criterion, optimizer, config.accum_steps)\n",
    "    stats = validate_and_save(model, task, criterion, optimizer, epoch=epoch_itr.epoch)\n",
    "    logger.info(\"end of epoch {}\".format(epoch_itr.epoch))    \n",
    "    epoch_itr = load_data_iterator(task, \"train\", epoch_itr.next_epoch_idx, config.max_tokens, config.num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyjRwllxPjtf"
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N70Gc6smPi1d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(checkpoint_upper_bound=None, inputs=['./checkpoints/transformer'], num_epoch_checkpoints=5, num_update_checkpoints=None, output='./checkpoints/transformer/avg_last_5_checkpoint.pt')\n",
      "averaging checkpoints:  ['./checkpoints/transformer/checkpoint30.pt', './checkpoints/transformer/checkpoint29.pt', './checkpoints/transformer/checkpoint28.pt', './checkpoints/transformer/checkpoint27.pt', './checkpoints/transformer/checkpoint26.pt']\n",
      "Finished writing averaged checkpoint to ./checkpoints/transformer/avg_last_5_checkpoint.pt\n"
     ]
    }
   ],
   "source": [
    "# averaging a few checkpoints can have a similar effect to ensemble\n",
    "checkdir=config.savedir\n",
    "!python ./fairseq/scripts/average_checkpoints.py \\\n",
    "--inputs {checkdir} \\\n",
    "--num-epoch-checkpoints 5 \\\n",
    "--output {checkdir}/avg_last_5_checkpoint.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAGMiun8PnZy"
   },
   "source": [
    "## Confirm model weights used to generate submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tvRdivVUPnsU",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 05:04:54 | INFO | hw5.seq2seq | loaded checkpoint checkpoints/transformer/avg_last_5_checkpoint.pt: step=unknown loss=3.869950771331787 bleu=26.14941607337366\n",
      "loaded checkpoint checkpoints/transformer/avg_last_5_checkpoint.pt: step=unknown loss=3.869950771331787 bleu=26.14941607337366\n",
      "2024-01-07 05:04:54 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005396842956542969,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "validation",
       "rate": null,
       "total": 90,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 05:06:21 | INFO | hw5.seq2seq | example source: 'fan , as a person , also needs to live , ' the spokesman told xinhua . 'we hope the media will be tolerant about fan and give him some living space . '\n",
      "2024-01-07 05:06:21 | INFO | hw5.seq2seq | example hypothesis: 发言人对新华社说 , 范先生 , 作为一个人 , 还需要生活 。 我们希望媒体能容忍球迷 , 并给他一些生活空间 。\n",
      "2024-01-07 05:06:21 | INFO | hw5.seq2seq | example reference: 这位人士对新华社表示 , 范美忠是个人 , 也需要生活 。 我们希望媒体能宽容他 , 给他一点生存空间 。\n",
      "2024-01-07 05:06:21 | INFO | hw5.seq2seq | validation loss:\t3.8305\n",
      "2024-01-07 05:06:21 | INFO | hw5.seq2seq | BLEU = 26.63 63.3/36.9/22.8/14.9 (BP = 0.891 ratio = 0.897 hyp_len = 590451 ref_len = 658487)\n"
     ]
    }
   ],
   "source": [
    "# checkpoint_last.pt : latest epoch\n",
    "# checkpoint_best.pt : highest validation bleu\n",
    "# avg_last_5_checkpoint.pt:　the average of last 5 epochs\n",
    "try_load_checkpoint(model, name=\"avg_last_5_checkpoint.pt\")\n",
    "validate(model, task, criterion, log_to_wandb=False)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ioAIflXpPsxt"
   },
   "source": [
    "## Generate Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oYMxA8FlPtIq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_prediction(model, task, split=\"test\", outfile=\"./prediction.txt\"):    \n",
    "    task.load_dataset(split=split, epoch=1)\n",
    "    itr = load_data_iterator(task, split, 1, config.max_tokens, config.num_workers).next_epoch_itr(shuffle=False)\n",
    "    \n",
    "    idxs = []\n",
    "    hyps = []\n",
    "\n",
    "    model.eval()\n",
    "    progress = tqdm.tqdm(itr, desc=f\"prediction\")\n",
    "    with torch.no_grad():\n",
    "        for i, sample in enumerate(progress):\n",
    "            # validation loss\n",
    "            sample = utils.move_to_cuda(sample, device=device)\n",
    "\n",
    "            # do inference\n",
    "            s, h, r = inference_step(sample, model)\n",
    "            \n",
    "            hyps.extend(h)\n",
    "            idxs.extend(list(sample['id']))\n",
    "            \n",
    "    # sort based on the order before preprocess\n",
    "    hyps = [x for _,x in sorted(zip(idxs,hyps))]\n",
    "    \n",
    "    with open(outfile, \"w\") as f:\n",
    "        for h in hyps:\n",
    "            f.write(h+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Le4RFWXxjmm0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_prediction(model, task)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "nKb4u67-sT_Z",
    "n1rwQysTsdJq",
    "59si_C0Wsms7",
    "oOpG4EBRLwe_",
    "6ZlE_1JnMv56",
    "UDAPmxjRNEEL",
    "ce5n4eS7NQNy",
    "rUB9f1WCNgMH",
    "VFJlkOMONsc6",
    "Gt1lX3DRO_yU",
    "BAGMiun8PnZy",
    "JOVQRHzGQU4-",
    "jegH0bvMQVmR",
    "a65glBVXQZiE",
    "smA0JraEQdxz",
    "Jn4XeawpQjLk"
   ],
   "name": "HW05.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
